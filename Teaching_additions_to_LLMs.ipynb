{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80517dbc",
   "metadata": {
    "id": "80517dbc"
   },
   "source": [
    "# Teach an LLM to do additions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aaca18f",
   "metadata": {},
   "source": [
    "The goal of this project is to teach an LLM to do additions, playing only with two parts:\n",
    "* the tokenizer\n",
    "* the positional embedding\n",
    "\n",
    "Both the model and the dataset are fixed.\n",
    "\n",
    "You are allowed to tune the hyperparameters, but this is not the main goal. Depending on the quality of your tokenizer and positional embedding, you may change the number of bits. The initial value of 3 is very small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ae993bb9",
   "metadata": {
    "id": "ae993bb9"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "739b5d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "OzGh9ahKF17h",
   "metadata": {
    "id": "OzGh9ahKF17h"
   },
   "outputs": [],
   "source": [
    "number_bits = 3\n",
    "\n",
    "dataset_size = 64_000\n",
    "train_proportion = 0.9\n",
    "\n",
    "log_interval = 200\n",
    "batch_size = 64\n",
    "epochs = 4\n",
    "learning_rate = 8e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c054bed",
   "metadata": {
    "id": "6c054bed"
   },
   "source": [
    "## Step 1: Construct a tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "t6aC9uNeIR6C",
   "metadata": {
    "id": "t6aC9uNeIR6C"
   },
   "outputs": [],
   "source": [
    "pad_token=\"[PAD]\"\n",
    "eos_token=\"[EOS]\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BMvT0B-MGBnY",
   "metadata": {
    "id": "BMvT0B-MGBnY"
   },
   "source": [
    "### Baseline: character-level tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "g2QiF-otFur3",
   "metadata": {
    "id": "g2QiF-otFur3"
   },
   "outputs": [],
   "source": [
    "class character_level_tokenizer:\n",
    "    \"\"\"\n",
    "    character-level\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.vocab = [str(x) for x in range(10)] + [\"+\", \"=\"] + [pad_token, eos_token]\n",
    "        self.token_to_id = {v : k for k, v in enumerate(self.vocab)}\n",
    "        self.id_to_token = {k : v for k, v in enumerate(self.vocab)}\n",
    "        self.ntokens = len(self.vocab)\n",
    "        self.pattern = f\"[^{re.escape(''.join(self.vocab))}]\"\n",
    "    \n",
    "    def clean(self, text):\n",
    "        \"\"\"\n",
    "        removes all characters not in the vocabulary\n",
    "        \"\"\"\n",
    "        out = re.sub(self.pattern, \"\", text)\n",
    "        return out\n",
    "\n",
    "    def pre_tokenization(self, text):\n",
    "        \"\"\"\n",
    "        character-level\n",
    "        \"\"\"\n",
    "        return [c for c in text]\n",
    "\n",
    "    def encode(self, text):\n",
    "        text_list = self.pre_tokenization(self.clean(text))\n",
    "        return [self.token_to_id[c] for c in text_list]\n",
    "\n",
    "    def decode(self, token_list):\n",
    "        return \"\".join([self.id_to_token[x] for x in token_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "QuCc6jF5F8hK",
   "metadata": {
    "id": "QuCc6jF5F8hK"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_tokenizer = character_level_tokenizer()\n",
    "ntokens = base_tokenizer.ntokens\n",
    "ntokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8FXW2K-1Jd-P",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8FXW2K-1Jd-P",
    "outputId": "349a4033-9fce-462b-f0d5-1bb3a7ffd340"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1, 2, 10, 4, 2, 11], '12+42=')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"12 + 42 =\"\n",
    "inputs = base_tokenizer.encode(prompt)\n",
    "inputs, base_tokenizer.decode(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "j3gckvebGGYt",
   "metadata": {
    "id": "j3gckvebGGYt"
   },
   "source": [
    "# Implement your tokenizer here!\n",
    "\n",
    "You can do anything (as long as you do not compute the addition!).\n",
    "Some ideas:\n",
    "* reversing numbers left to right\n",
    "* arranging by groups (of, 2, 3,...)\n",
    "* aligning numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ae2b58",
   "metadata": {},
   "source": [
    "Mon idée est que lorsque l'on faisait des opérations arithmétiques en primaire, on calculait dizaine par dizaine, avec des retenues. On traite donc les chiffres individuellement, mais à la dizaine pertinente. Ainsi, ici, je propose d'encoder chaque chiffre d'un nombre mais en donnant son unité. Par exemple, \"123\" sera tokénisé en [\"100\", \"20\", \"3\"]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "91245f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class advanced_tokenizer:\n",
    "    \"\"\"\n",
    "    Encodes numbers as a sequence of digits of variable length depending of their Power of 10\n",
    "    (e.g. 123 is encoded as 100, 20, 3)\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialises the tokenizer. \n",
    "        The vocabulary is all numbers of the form [digit]00...0 , +, =, [PAD], [EOS]\n",
    "        0 is explicited added to the vocabulary to avoid repetition of the same number\n",
    "        We make available in the vocabulary number of n_bits + 1 digits\"\"\"\n",
    "\n",
    "        self.vocab = [\"0\"] + [str(x * 10 ** k) for x in range(1, 10) for k in range(number_bits +1)] + [\"+\", \"=\"] + [pad_token, eos_token] \n",
    "        self.token_to_id = {v : k for k, v in enumerate(self.vocab)}\n",
    "        self.id_to_token = {k : v for k, v in enumerate(self.vocab)}\n",
    "        self.ntokens = len(self.vocab)\n",
    "        self.pattern = r'[^0-9+=]' # Permet de ne garder que les chiffres, + et = et éviter la fragmentation des nombres à plusieurs chiffres (e.g. 100, 20 ,etc.)\n",
    "    \n",
    "    def clean(self, text):\n",
    "        \"\"\"\n",
    "        removes all characters not in the vocabulary\n",
    "        \"\"\"\n",
    "        out = re.sub(self.pattern, \"\", text)\n",
    "        return out\n",
    "\n",
    "    def pre_tokenization(self, text):\n",
    "        \"\"\"\n",
    "        transforms the text into a list of tokens\n",
    "        a number is a sequence of digits that are encoded with their corresponding number in the vocabulary\n",
    "        for example, 12 is encoded as 10, 2\n",
    "        \"\"\"\n",
    "        number_length = 0\n",
    "        text_list = []\n",
    "        number_digits_list = []\n",
    "        for c in text:\n",
    "            if c in self.vocab:\n",
    "                if c == \"0\" and number_length == 0:\n",
    "                    continue # avoid adding 0 at the beginning of a number to not confuse the model\n",
    "                elif c not in [str(x) for x in range(10)] and number_length == 0: # case for + and =\n",
    "                    text_list.append(c)\n",
    "                elif c in [str(x) for x in range(0, 10)]: # if c is a digit\n",
    "                    number_digits_list.append(c)\n",
    "                    number_length += 1\n",
    "                #elif c == \"0\" and number_length > 0: # if c is a 0 in the middle of a number\n",
    "                 #   number_length += 1 # avoid to have repeated 0 in the middle of a number\n",
    "                else : # at the end of a number\n",
    "                    if number_length > 0:\n",
    "                        for i in range(number_length):\n",
    "                            text_list.append(str(10 ** (number_length - i - 1) * int(number_digits_list[i])))\n",
    "                        number_digits_list = []\n",
    "                        number_length = 0\n",
    "                    text_list.append(c)\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        if number_length > 0: # if the number is at the end of the text (not supposed to happen)\n",
    "            for i in range(number_length):\n",
    "                text_list.append(str(10 ** (number_length - i - 1) * int(number_digits_list[i])))\n",
    "\n",
    "\n",
    "        return text_list\n",
    "\n",
    "\n",
    "    def encode(self, text):\n",
    "        text_list = self.pre_tokenization(self.clean(text))\n",
    "        return [self.token_to_id[c] for c in text_list]\n",
    "\n",
    "    def decode(self, token_list):\n",
    "        \"\"\"Decoder\"\"\"\n",
    "        output = []\n",
    "        for x in token_list:\n",
    "            if x > 9 * (number_bits +1): # if x is not corresponding to a number\n",
    "                output.append(self.id_to_token[x])\n",
    "            else:\n",
    "                output.append(self.id_to_token[x][0])\n",
    "        return \"\".join(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a96f3517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary:  ['0', '1', '10', '100', '1000', '2', '20', '200', '2000', '3', '30', '300', '3000', '4', '40', '400', '4000', '5', '50', '500', '5000', '6', '60', '600', '6000', '7', '70', '700', '7000', '8', '80', '800', '8000', '9', '90', '900', '9000', '+', '=', '[PAD]', '[EOS]']\n",
      "pretokenisation of 12 + 42 = :  ['10', '2', '+', '40', '2', '=']\n"
     ]
    }
   ],
   "source": [
    "print(\"vocabulary: \", advanced_tokenizer().vocab)\n",
    "print(\"pretokenisation of 12 + 42 = : \", advanced_tokenizer().pre_tokenization(\"12 + 42 =\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ba7c3a62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = advanced_tokenizer()\n",
    "ntokens = tokenizer.ntokens\n",
    "ntokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "71d34c9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([2, 5, 37, 14, 5, 38], '12+42=')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"12 + 42 =\"\n",
    "inputs = tokenizer.encode(prompt)\n",
    "inputs, tokenizer.decode(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491af297",
   "metadata": {
    "id": "491af297"
   },
   "source": [
    "## Step 2: Create a dataset for arithmetic operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "daa90f31",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "daa90f31",
    "outputId": "3e8719ee-d8fa-4984-8b51-4db3457f7dbc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('60+402=', '462')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sample_datapoint(number_bits = 3):\n",
    "    \"\"\"\n",
    "    returns a string containing two random numbers on `number_bits` many bits and their sum.\n",
    "    \"\"\"\n",
    "    a_list = [random.randint(0, 9) for _ in range(number_bits)]\n",
    "    b_list = [random.randint(0, 9) for _ in range(number_bits)]\n",
    "    a_int = int(\"\".join([str(x) for x in a_list]))\n",
    "    b_int = int(\"\".join([str(x) for x in b_list]))\n",
    "    sum_int = a_int + b_int\n",
    "    return (str(a_int) + \"+\" + str(b_int) + \"=\", str(sum_int))\n",
    "\n",
    "sample_datapoint(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b6e861d2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b6e861d2",
    "outputId": "c88c2226-0546-473c-c296-88a52823886b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('485+620=', '1105'),\n",
       " ('412+173=', '585'),\n",
       " ('254+465=', '719'),\n",
       " ('130+837=', '967')]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "for _ in range(dataset_size):\n",
    "    data.append(sample_datapoint(number_bits))\n",
    "data[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fee85050",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fee85050",
    "outputId": "f080f4b0-fd76-48d8-d59f-7c118b6e6fe9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57600, 6400)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = data[: int(train_proportion * dataset_size)]\n",
    "data_test = data[int(train_proportion * dataset_size):]\n",
    "\n",
    "len(data_train),len(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37200598",
   "metadata": {
    "id": "37200598"
   },
   "source": [
    "## Step 3: Construct a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd7d2eb",
   "metadata": {},
   "source": [
    "### Basline: the classical Positional Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "91674239",
   "metadata": {
    "id": "91674239"
   },
   "outputs": [],
   "source": [
    "class PositionalEmbedding(nn.Module):\n",
    "    r\"\"\"Inject some information about the relative or absolute position of the tokens in the sequence.\n",
    "        The positional encodings have the same dimension as the embeddings, so that the two can be summed.\n",
    "        Here, we use sine and cosine functions of different frequencies.\n",
    "    .. math:\n",
    "        \\text{PosEmbedder}(pos, 2i) = sin(pos/10000^(2i/d_model))\n",
    "        \\text{PosEmbedder}(pos, 2i+1) = cos(pos/10000^(2i/d_model))\n",
    "        \\text{where pos is the word position and i is the embed idx)\n",
    "    Args:\n",
    "        d_model: the embed dim (required).\n",
    "        dropout: the dropout value (default=0.1).\n",
    "        max_len: the max. length of the incoming sequence (default=5000).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEmbedding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        r\"\"\"Inputs of forward function\n",
    "        Args:\n",
    "            x: the sequence fed to the positional encoder model (required).\n",
    "        Shape:\n",
    "            x: [sequence length, batch size, embed dim]\n",
    "            output: [sequence length, batch size, embed dim]\n",
    "        \"\"\"\n",
    "\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0534e4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseTransformerModel(nn.Transformer):\n",
    "    def __init__(self, ntoken, ninp, nhead, nhid, nlayers, dropout=0.5):\n",
    "        super(BaseTransformerModel, self).__init__(d_model=ninp,\n",
    "                                               nhead=nhead,\n",
    "                                               dim_feedforward=nhid,\n",
    "                                               num_encoder_layers=nlayers)\n",
    "        self.input_emb = nn.Embedding(ntoken, ninp)\n",
    "        self.pos_encoder = PositionalEmbedding(ninp, dropout)\n",
    "        self.decoder = nn.Linear(ninp, ntoken)\n",
    "\n",
    "        self.ninp = ninp\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        nn.init.uniform_(self.input_emb.weight, -initrange, initrange)\n",
    "        nn.init.zeros_(self.decoder.bias)\n",
    "        nn.init.uniform_(self.decoder.weight, -initrange, initrange)\n",
    "\n",
    "    def _generate_square_subsequent_mask(self, sz):\n",
    "        return torch.log(torch.tril(torch.ones(sz,sz)))\n",
    "\n",
    "    def forward(self, src):\n",
    "        mask = self._generate_square_subsequent_mask(len(src)).to(device)\n",
    "        self.src_mask = mask\n",
    "\n",
    "        src = self.input_emb(src) * math.sqrt(self.ninp)\n",
    "        # Passage à la positional encoder en fournissant les token ids\n",
    "        src = self.pos_encoder(src)\n",
    "        output_enc = self.encoder(src, mask=self.src_mask)\n",
    "        output_dec = self.decoder(output_enc)\n",
    "        return F.log_softmax(output_dec, dim=-1), output_enc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8296ceb2",
   "metadata": {},
   "source": [
    "# Implement your positional embedding here!\n",
    "\n",
    "You can do anything. Some ideas:\n",
    "* RoPE\n",
    "* (randomised) FIRE\n",
    "* Abacus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d14d1fe",
   "metadata": {},
   "source": [
    "Pour bien correspondre avec le tokeniseur que nous avons implémenté, nous allons utiliser un embedding inspiré d'un Abacus. L'idée est d'indiquer à chaque composante sa puissance de 10 en décomposant les nombre en niveaux hiérarchiques (centaines, dizaines, unités) et permettrait de renforcer les informations d'unité sur les nombres. Ainsi, par exemple 300 recevra l'embedding (2, 3) car $300 = 3 \\times 10^2$. Cela permet d'avoir toutes les informations sur un nombre. J'ai testé le modèle avec et sans l'ajout de l'information de l'unité dans le masque et je remarque que l'ajout de l'unité dans le masque améliore les choses en donnant des résultats plus proches (même accuracy, mais bien moins grande distance)./\n",
    "\n",
    "Concernant l'usage de l'abacus, celui que je propose est un peu différent, puisqu'il est dans les articles et codes que j'ai vu (nottament https://seunghan96.github.io/llm/nlp/AriTrans/ et https://github.com/mcleish7/arithmetic). En effet, les articles l'utilisant préfèrent le combiner avec un tokéniseur qui se contente de renverser l'ordre de traitement pour mettre d'abord les nombres les plus importants (par exemple 123 est tokénisé en \"321\"). Il s'agit donc, à ma connaissance d'un travail de recherche nouveau sur la question.\n",
    "\n",
    "Comme dans la baseline, nous utilisons nn.dropout pour éviter une trop grande adaptation des réseaux de neurone (Les raisons de cela sont bien expliquées dans la documentation: https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "79604911",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AbacusPositionalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.5, max_len=5000, tokenizer=tokenizer):\n",
    "        \"\"\"\n",
    "        d_model   : dimension des embeddings\n",
    "        dropout   : taux de dropout\n",
    "        max_len   : longueur maximale des séquences pour la positional encoding classique\n",
    "        tokenizer : instance du tokenizer pour récupérer le vocabulaire et construire la table d'exposants\n",
    "        \"\"\"\n",
    "        super(AbacusPositionalEmbedding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.tokenizer = tokenizer\n",
    "       \n",
    "        exponent_table = []\n",
    "        mantissa_table = []\n",
    "        numeric_mask = []  # 1 pour token numérique (hors \"0\"), 0 sinon.\n",
    "        max_exponent = 0\n",
    "        for token_id, token in tokenizer.id_to_token.items():\n",
    "            if token.isdigit() and token not in [pad_token, eos_token, \"+\", \"=\"]:\n",
    "                if token == \"0\":\n",
    "                    exponent_table.append(0)\n",
    "                    numeric_mask.append(0)\n",
    "                    mantissa_table.append(0)\n",
    "                else:\n",
    "                    exp =  len(token) - 1  # \"2\" -> 0, \"20\" -> 1, \"300\" -> 2, etc. \n",
    "                    #exp = number_bits - len(token) + 1 # \"2\" -> 2, \"20\" -> 1, \"300\" -> 0, etc. : autre option pour utiliser le même principe que les nombres binaires (cf. sources plus haut)\n",
    "                    exponent_table.append(exp)\n",
    "                    mantissa_table.append(int(token[0]))\n",
    "                    numeric_mask.append(1)\n",
    "                    max_exponent = max(max_exponent, exp)\n",
    "            else:\n",
    "                exponent_table.append(0)\n",
    "                numeric_mask.append(0)\n",
    "                mantissa_table.append(0)\n",
    "\n",
    "        self.register_buffer('exponent_table', torch.tensor(exponent_table, dtype=torch.long))\n",
    "        self.register_buffer('numeric_mask', torch.tensor(numeric_mask, dtype=torch.float))\n",
    "        self.register_buffer('mantissa_table', torch.tensor(mantissa_table, dtype=torch.long))\n",
    "        # Embedding simple pour les exposants allant de 0 à max_exponent\n",
    "        self.exp_embedding = nn.Embedding(max_exponent + 1, d_model)\n",
    "        self.mant_embedding = nn.Embedding(10, d_model)\n",
    "\n",
    "    def forward(self, x, token_ids=None):\n",
    "        \"\"\"\n",
    "        x         : Tensor de shape (seq_len, batch_size, d_model) (output de l'embedding d'entrée)\n",
    "        token_ids : Tensor de shape (seq_len, batch_size) contenant les indices originaux (utilisés pour l'abacus)\n",
    "                    On ajoute l'information abacus.\n",
    "        \"\"\"\n",
    "        \n",
    "        token_ids = token_ids.long()\n",
    "        # Récupère pour chaque token son exposant depuis la table\n",
    "        exponents = self.exponent_table[token_ids]       # shape : (seq_len, batch_size)\n",
    "        mantissas = self.mantissa_table[token_ids]       # shape : (seq_len, batch_size)\n",
    "        mask = self.numeric_mask[token_ids].unsqueeze(-1)  # shape : (seq_len, batch_size, 1)\n",
    "        exp_emb = self.exp_embedding(exponents)            # shape : (seq_len, batch_size, d_model)\n",
    "        mant_emb = self.mant_embedding(mantissas)            # shape : (seq_len, batch_size, d_model)\n",
    "        x = x + (exp_emb + mant_emb) * mask # Ajout de l'information abacus\n",
    "        x = x + exp_emb * mask \n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc72868",
   "metadata": {},
   "source": [
    "### Transformer model\n",
    "\n",
    "**!!! IMPORTANT !!!** This model of Transformers is \"input first\", meaning that an input is a tensor with shape\n",
    "(length_prompts, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4eb278ab",
   "metadata": {
    "id": "4eb278ab"
   },
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Transformer):\n",
    "    def __init__(self, ntoken, ninp, nhead, nhid, nlayers, dropout=0.5):\n",
    "        super(TransformerModel, self).__init__(d_model=ninp,\n",
    "                                               nhead=nhead,\n",
    "                                               dim_feedforward=nhid,\n",
    "                                               num_encoder_layers=nlayers)\n",
    "        self.input_emb = nn.Embedding(ntoken, ninp)\n",
    "        self.pos_encoder = AbacusPositionalEmbedding(ninp, dropout)\n",
    "        self.decoder = nn.Linear(ninp, ntoken)\n",
    "\n",
    "        self.ninp = ninp\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        nn.init.uniform_(self.input_emb.weight, -initrange, initrange)\n",
    "        nn.init.zeros_(self.decoder.bias)\n",
    "        nn.init.uniform_(self.decoder.weight, -initrange, initrange)\n",
    "\n",
    "    def _generate_square_subsequent_mask(self, sz):\n",
    "        return torch.log(torch.tril(torch.ones(sz,sz)))\n",
    "\n",
    "    def forward(self, src):\n",
    "        mask = self._generate_square_subsequent_mask(len(src)).to(device)\n",
    "        self.src_mask = mask\n",
    "\n",
    "        # Calcul de l'embedding d'entrée\n",
    "        emb = self.input_emb(src) * math.sqrt(self.ninp)\n",
    "        # Passage à la positional encoder en fournissant les token ids\n",
    "        src = self.pos_encoder(emb, token_ids=src)\n",
    "        output_enc = self.encoder(src, mask=self.src_mask)\n",
    "        output_dec = self.decoder(output_enc)\n",
    "        return F.log_softmax(output_dec, dim=-1), output_enc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30e093a",
   "metadata": {},
   "source": [
    "Please do not change these parameters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1d568cc4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1d568cc4",
    "outputId": "f7f78975-2bdf-4c36-de35-3e140636d476"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adminialab/miniconda3/envs/llm_env/lib/python3.13/site-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = TransformerModel(ntoken = ntokens,\n",
    "                         ninp = 128,\n",
    "                         nhead = 16,\n",
    "                         nhid = 64,\n",
    "                         nlayers = 8)\n",
    "model.to(device)\n",
    "\n",
    "tokenizer = tokenizer # Choisir le tokeniser\n",
    "ntokens = tokenizer.ntokens # Nombre de tokens dans le vocabulaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8f2f06e0",
   "metadata": {
    "id": "8f2f06e0"
   },
   "outputs": [],
   "source": [
    "def generate(model, prompts, new_tokens = 5):\n",
    "    input_tensor = prompts # (length_prompts, batch_size)\n",
    "    input_tensor = input_tensor.to(device)\n",
    "\n",
    "     # Debug: Print initial tensor shape\n",
    "    #print(f\"Initial input_tensor shape: {input_tensor.shape}\")\n",
    "    \n",
    "    for _ in range(new_tokens):\n",
    "        output, _ = model(input_tensor) # (length_prompts, batch_size, ntokens)\n",
    "\n",
    "        # Debug: Print output tensor shape\n",
    "        #print(f\"Output tensor shape: {output.shape}\")\n",
    "\n",
    "        last_output = output[-1,:,:] # (batch_size, ntokens)\n",
    "        token = torch.argmax(last_output, -1).view((1,-1)) # (1, batch_size)\n",
    "        input_tensor = torch.cat((input_tensor, token), 0)\n",
    "    return input_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d76d1b19",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d76d1b19",
    "outputId": "a1df1dc9-2ecc-4de4-85b2-6bc5bd460439"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 5, 37,  9, 38, 37, 37, 37, 37, 37]], device='cuda:0'), '2+3=+++++')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "prompt = \"2+3=\"\n",
    "prompt_tensor = torch.tensor(tokenizer.encode(prompt)).view((-1,1))\n",
    "output = generate(model, prompt_tensor).view((1,-1))\n",
    "output, tokenizer.decode(output.tolist()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "00954ddc",
   "metadata": {
    "id": "00954ddc"
   },
   "outputs": [],
   "source": [
    "def pad(token_list, type_list = \"prompts\"):\n",
    "    max_length = max([len(x) for x in token_list])\n",
    "    out = []\n",
    "    for x in token_list:\n",
    "        if type_list == \"prompts\":\n",
    "            out.append([tokenizer.token_to_id[pad_token]] * (max_length - len(x)) + x)\n",
    "        if type_list == \"answers\":\n",
    "            out.append(x + [tokenizer.token_to_id[eos_token]] + [tokenizer.token_to_id[pad_token]] * (max_length - len(x)))\n",
    "    return out, max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2c84beab",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2c84beab",
    "outputId": "fc1bea13-d6e1-4a55-b70d-36de00bcec9b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['[PAD][PAD]1+1=', '21+35='], ['2[EOS][PAD]', '56[EOS]'])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts = [tokenizer.encode(\"1+1=\"), tokenizer.encode(\"21+35=\")]\n",
    "answers = [tokenizer.encode(\"2\"), tokenizer.encode(\"56\")]\n",
    "padded_prompts, _ = pad(prompts, \"prompts\")\n",
    "padded_answers, _ = pad(answers, \"answers\")\n",
    "padded_prompts, padded_answers\n",
    "[tokenizer.decode(p) for p in padded_prompts], [tokenizer.decode(p) for p in padded_answers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "264f9227",
   "metadata": {
    "id": "264f9227"
   },
   "outputs": [],
   "source": [
    "def get_batch(split, i):\n",
    "    data = data_train if split == 'train' else data_test\n",
    "    prompts = [tokenizer.encode(data[i][0]) for i in range(i, i + batch_size)]\n",
    "    padded_prompts, length_prompts = pad(prompts, \"prompts\")\n",
    "    answers = [tokenizer.encode(data[i][1]) for i in range(i, i + batch_size)]\n",
    "    padded_answers, length_answers = pad(answers, \"answers\")\n",
    "    X = torch.stack([torch.tensor(x) for x in padded_prompts], 1)\n",
    "    Y = torch.stack([torch.tensor(x) for x in padded_answers], 1)\n",
    "    return X, Y, length_prompts, length_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "91e281ad",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "91e281ad",
    "outputId": "22e2d0ee-ede4-41f8-e089-fb63ac2d9787"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 64]), torch.Size([5, 64]), 8, 4)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, Y, length_prompts, length_answers = get_batch(\"train\", 243)\n",
    "X.shape, Y.shape, length_prompts, length_answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113e1fd1",
   "metadata": {
    "id": "113e1fd1"
   },
   "source": [
    "## Step 4: Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1cfcd10a",
   "metadata": {
    "id": "1cfcd10a"
   },
   "outputs": [],
   "source": [
    "def evaluate():\n",
    "    # Turn on evaluation mode disables dropout.\n",
    "    model.eval()\n",
    "    correct = 0.\n",
    "    with torch.no_grad():\n",
    "        for batch, i in enumerate(range(0, len(data_test) - 1, batch_size)):\n",
    "            prompts, target_answers, length_prompts, length_answers = get_batch(\"test\", i)\n",
    "            prompts = prompts.to(device) # (length_prompts, batch_size)\n",
    "            target_answers = target_answers.to(device) # (length_answers + 1, batch_size)\n",
    "            output = generate(model, prompts, length_answers + 1) # (length_prompts + length_answers + 1, batch_size)\n",
    "            answers_tokens = output[length_prompts:, :] # (length_answers + 1, batch_size), contains tokens\n",
    "            equality_test = answers_tokens == target_answers # (length_answers + 1, batch_size), contains boolean values\n",
    "            correct += torch.all(equality_test, axis=0).float().sum()\n",
    "        accuracy = correct / len(data_test)\n",
    "    return accuracy.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ac335b05",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ac335b05",
    "outputId": "b475e943-51b3-401d-d18b-c9d32a49ffb6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c54061a",
   "metadata": {
    "id": "4c54061a"
   },
   "source": [
    "## Step 4: Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3638a75d",
   "metadata": {
    "id": "3638a75d"
   },
   "outputs": [],
   "source": [
    "def train_epoch():\n",
    "    model.train()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    total_loss = 0.\n",
    "    start_time = time.time()\n",
    "    for batch, i in enumerate(range(0, len(data_train) - 1, batch_size)):\n",
    "        prompts, target_answers, length_prompts, length_answers = get_batch(\"train\", i)\n",
    "        prompts = prompts.to(device) # (length_prompts, batch_size)\n",
    "        target_answers = target_answers.to(device) # (length_answers, batch_size)\n",
    "        input_tensor = torch.cat((prompts, target_answers), 0) # (length_prompts + length_answers, batch_size)\n",
    "        model.zero_grad()\n",
    "        output, _ = model(input_tensor) # (length_prompts + length_answers, batch_size, ntokens)\n",
    "        output_answers = output[length_prompts-1:-1,:,:].reshape(-1, ntokens) # (length_answers * batch_size, ntokens)\n",
    "        target_answers = target_answers.view(-1)\n",
    "        loss = F.cross_entropy(output_answers, target_answers)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        if batch % log_interval == 0 and batch > 0:\n",
    "            cur_loss = total_loss / log_interval\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| {:5d}/{:5d} batches | ms/batch {:5.2f} | loss {:5.2f} | perplexity {:8.2f}'.format(batch, len(data_train) // batch_size,\n",
    "                                                                                                        elapsed * 1000 / log_interval, cur_loss, math.exp(cur_loss)))\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "\n",
    "def train():\n",
    "    best_test_accuracy = None\n",
    "    test_accuracy = evaluate()\n",
    "    print('-' * 89)\n",
    "    print('| initialisation | test accuracy {:5.2f}'.format(test_accuracy))\n",
    "    print('-' * 89)\n",
    "    for epoch in range(1, epochs+1):\n",
    "        epoch_start_time = time.time()\n",
    "        train_epoch()\n",
    "        test_accuracy = evaluate()\n",
    "        print('-' * 89)\n",
    "        print('| end of epoch {:3d} | time: {:5.2f}s | test accuracy {:5.2f}'.format(epoch, (time.time() - epoch_start_time), test_accuracy))\n",
    "        print('-' * 89)\n",
    "        # Save the model if the test accuracy is the best we've seen so far.\n",
    "        if not best_test_accuracy or test_accuracy < best_test_accuracy:\n",
    "            with open(\"arithmetic.pt\", 'wb') as f:\n",
    "                torch.save(model, f)\n",
    "            best_test_accuracy = test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4e2a8490",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4e2a8490",
    "outputId": "f70dcac2-5891-4266-8748-85df050f4881"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------\n",
      "| initialisation | test accuracy  0.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "|   200/  900 batches | ms/batch 17.65 | loss  1.75 | perplexity     5.78\n",
      "|   400/  900 batches | ms/batch 17.97 | loss  1.24 | perplexity     3.46\n",
      "|   600/  900 batches | ms/batch 17.64 | loss  1.17 | perplexity     3.23\n",
      "|   800/  900 batches | ms/batch 17.77 | loss  1.14 | perplexity     3.12\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time: 18.09s | test accuracy  0.01\n",
      "-----------------------------------------------------------------------------------------\n",
      "|   200/  900 batches | ms/batch 17.55 | loss  1.11 | perplexity     3.03\n",
      "|   400/  900 batches | ms/batch 17.42 | loss  1.08 | perplexity     2.94\n",
      "|   600/  900 batches | ms/batch 17.75 | loss  1.06 | perplexity     2.88\n",
      "|   800/  900 batches | ms/batch 17.54 | loss  1.00 | perplexity     2.72\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   2 | time: 17.95s | test accuracy  0.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "|   200/  900 batches | ms/batch 17.64 | loss  0.85 | perplexity     2.34\n",
      "|   400/  900 batches | ms/batch 17.56 | loss  0.79 | perplexity     2.20\n",
      "|   600/  900 batches | ms/batch 17.43 | loss  0.76 | perplexity     2.13\n",
      "|   800/  900 batches | ms/batch 17.54 | loss  0.73 | perplexity     2.08\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   3 | time: 17.96s | test accuracy  0.07\n",
      "-----------------------------------------------------------------------------------------\n",
      "|   200/  900 batches | ms/batch 17.63 | loss  0.71 | perplexity     2.03\n",
      "|   400/  900 batches | ms/batch 17.49 | loss  0.67 | perplexity     1.96\n",
      "|   600/  900 batches | ms/batch 17.54 | loss  0.65 | perplexity     1.92\n",
      "|   800/  900 batches | ms/batch 17.38 | loss  0.63 | perplexity     1.89\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   4 | time: 17.97s | test accuracy  0.12\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "56d9d440",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "56d9d440",
    "outputId": "1872232b-b120-440b-e1a6-666e079efa3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "593+4=996\t actual result: 597\n",
      "555+979=1530\t actual result: 1534\n",
      "812+190=1007\t actual result: 1002\n",
      "356+380=737\t actual result: 736\n",
      "716+632=1347\t actual result: 1348\n",
      "531+114=647\t actual result: 645\n",
      "509+738=1240\t actual result: 1247\n",
      "579+29=100\t actual result: 608\n",
      "21+255=389\t actual result: 276\n",
      "979+240=1217\t actual result: 1219\n",
      "470+761=1237\t actual result: 1231\n",
      "595+127=722\t actual result: 722\n",
      "568+81=104\t actual result: 649\n",
      "832+371=1207\t actual result: 1203\n",
      "605+345=947\t actual result: 950\n",
      "782+556=1337\t actual result: 1338\n",
      "255+508=767\t actual result: 763\n",
      "504+322=827\t actual result: 826\n",
      "728+410=1137\t actual result: 1138\n",
      "368+693=1062\t actual result: 1061\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "for i in range(20):\n",
    "    prompt, answers = data_test[i]\n",
    "    prompt_tensor = torch.tensor(tokenizer.encode(prompt)).view((-1,1))\n",
    "    output = generate(model, prompt_tensor, len(answers)).view((1,-1))\n",
    "    print(tokenizer.decode(output.tolist()[0]) + \"\\t actual result: \" + answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qJ9IOZu8Xo4Y",
   "metadata": {
    "id": "qJ9IOZu8Xo4Y"
   },
   "source": [
    "## Probing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78be1213",
   "metadata": {},
   "source": [
    "This is just for fun..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "yomPfirhXkLb",
   "metadata": {
    "id": "yomPfirhXkLb"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_size = 1000\n",
    "test_size = 100\n",
    "\n",
    "model.eval()\n",
    "\n",
    "def data_probing(size):\n",
    "    X = []\n",
    "    y = np.zeros(size)\n",
    "    for i in range(size):\n",
    "        input = torch.tensor(tokenizer.encode(data[i][0])).view((-1, 1)).to(device)\n",
    "        _, output = model(input)\n",
    "        output = output[-1,:,:].flatten()\n",
    "        # determine whether there was a carry in the result:\n",
    "        carry = len(data[i][1]) > len(data[i][0]) / 2\n",
    "        X.append(output.cpu().detach().numpy())\n",
    "        y[i] = carry\n",
    "    return np.array(X), y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "QGmfXVxkppfP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QGmfXVxkppfP",
    "outputId": "6601c884-004f-40bb-8a1a-71995b17d860"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train, y_train = data_probing(train_size)\n",
    "X_test, y_test = data_probing(test_size)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "reg = LogisticRegression()\n",
    "reg.fit(X_train,y_train)\n",
    "reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f742ba6",
   "metadata": {},
   "source": [
    "## Implémentation classique\n",
    "\n",
    "Inspirée de SHEN, Ruoqi, BUBECK, Sébastien, ELDAN, Ronen, et al. Positional description matters for transformers arithmetic. arXiv preprint arXiv:2311.14737, 2023. Cela fonctionne moins bien dans notre implémentation que la solution proposée plus haut."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35601396",
   "metadata": {},
   "source": [
    "### Inverser l'ordre des nombres\n",
    "\n",
    "Dans les articles concernant les dernières méthodes de tokénisation il s'agit de l'approche préférée, pour combiner cela avec un abaccus (cf. plus bas). En voici une implémentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fe3232bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class inverse_tokenizer:\n",
    "    \"\"\"\n",
    "    Encodes numbers as a sequence of digits of variable length depending of their Power of 10\n",
    "    (e.g. 123 is encoded as 321)\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialises the tokenizer. \n",
    "        Identical to the baseline tokenizer\"\"\"\n",
    "\n",
    "        self.vocab = [str(x) for x in range(2*10**(number_bits))] + [\"+\", \"=\"] + [pad_token, eos_token]\n",
    "        self.token_to_id = {v : k for k, v in enumerate(self.vocab)}\n",
    "        self.id_to_token = {k : v for k, v in enumerate(self.vocab)}\n",
    "        self.ntokens = len(self.vocab)\n",
    "        self.pattern = f\"[^{re.escape(''.join(self.vocab))}]\"\n",
    "    \n",
    "    def clean(self, text):\n",
    "        \"\"\"\n",
    "        removes all characters not in the vocabulary\n",
    "        \"\"\"\n",
    "        out = re.sub(self.pattern, \"\", text)\n",
    "        return out\n",
    "\n",
    "    def pre_tokenization(self, text):\n",
    "        \"\"\"\n",
    "        transforms the text into a list of tokens\n",
    "        \"\"\"\n",
    "        number_length = 0\n",
    "        text_list = []\n",
    "        number_digits_list = []\n",
    "        for c in text:\n",
    "            if c in self.vocab:\n",
    "                if c == \"0\" and number_length == 0:\n",
    "                    continue # avoid adding 0 at the beginning of a number to not confuse the model\n",
    "                elif c not in [str(x) for x in range(10)] and number_length == 0: # case for + and =\n",
    "                    text_list.append(c)\n",
    "                elif c in [str(x) for x in range(0, 10)]: # if c is a digit\n",
    "                    number_digits_list.append(c)\n",
    "                    number_length += 1\n",
    "                else : # at the end of a number\n",
    "                    if number_length > 0:\n",
    "                        for i in range(number_length):\n",
    "                            #text_list.append(str(reversed(number_digits_list)))\n",
    "                            text_list.append(number_digits_list[number_length - i - 1])\n",
    "                        number_digits_list = []\n",
    "                        number_length = 0\n",
    "                    text_list.append(c)\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        if number_length > 0: # if the number is at the end of the text (not supposed to happen)\n",
    "            for i in range(number_length):\n",
    "                text_list.append(number_digits_list[number_length - i - 1])\n",
    "\n",
    "\n",
    "        return text_list\n",
    "\n",
    "\n",
    "    def encode(self, text):\n",
    "        text_list = self.pre_tokenization(self.clean(text))\n",
    "        return [self.token_to_id[c] for c in text_list]\n",
    "\n",
    "    def decode(self, token_list):\n",
    "        \"\"\"Decoder that removes the 0 at the end of a number\"\"\"\n",
    "        output = []\n",
    "        number_length = 0\n",
    "        number_list = []\n",
    "        for x in token_list:\n",
    "            if x > 9 and number_length > 0: # if x is not corresponding to a number\n",
    "                for i in range(number_length):\n",
    "                    output.append(self.id_to_token[number_list[number_length - i - 1]])\n",
    "                output.append(self.id_to_token[x])\n",
    "                number_list = []\n",
    "                number_length = 0\n",
    "            elif x > 9 and number_length == 0: # if x is not corresponding to a number\n",
    "                output.append(self.id_to_token[x])\n",
    "            else:\n",
    "                number_list.append(x)\n",
    "                number_length += 1\n",
    "        if number_length > 0:\n",
    "            for i in range(number_length):\n",
    "                output.append(self.id_to_token[number_list[number_length - i - 1]])\n",
    "\n",
    "        return \"\".join(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e59f1f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary:  ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '180', '181', '182', '183', '184', '185', '186', '187', '188', '189', '190', '191', '192', '193', '194', '195', '196', '197', '198', '199', '200', '201', '202', '203', '204', '205', '206', '207', '208', '209', '210', '211', '212', '213', '214', '215', '216', '217', '218', '219', '220', '221', '222', '223', '224', '225', '226', '227', '228', '229', '230', '231', '232', '233', '234', '235', '236', '237', '238', '239', '240', '241', '242', '243', '244', '245', '246', '247', '248', '249', '250', '251', '252', '253', '254', '255', '256', '257', '258', '259', '260', '261', '262', '263', '264', '265', '266', '267', '268', '269', '270', '271', '272', '273', '274', '275', '276', '277', '278', '279', '280', '281', '282', '283', '284', '285', '286', '287', '288', '289', '290', '291', '292', '293', '294', '295', '296', '297', '298', '299', '300', '301', '302', '303', '304', '305', '306', '307', '308', '309', '310', '311', '312', '313', '314', '315', '316', '317', '318', '319', '320', '321', '322', '323', '324', '325', '326', '327', '328', '329', '330', '331', '332', '333', '334', '335', '336', '337', '338', '339', '340', '341', '342', '343', '344', '345', '346', '347', '348', '349', '350', '351', '352', '353', '354', '355', '356', '357', '358', '359', '360', '361', '362', '363', '364', '365', '366', '367', '368', '369', '370', '371', '372', '373', '374', '375', '376', '377', '378', '379', '380', '381', '382', '383', '384', '385', '386', '387', '388', '389', '390', '391', '392', '393', '394', '395', '396', '397', '398', '399', '400', '401', '402', '403', '404', '405', '406', '407', '408', '409', '410', '411', '412', '413', '414', '415', '416', '417', '418', '419', '420', '421', '422', '423', '424', '425', '426', '427', '428', '429', '430', '431', '432', '433', '434', '435', '436', '437', '438', '439', '440', '441', '442', '443', '444', '445', '446', '447', '448', '449', '450', '451', '452', '453', '454', '455', '456', '457', '458', '459', '460', '461', '462', '463', '464', '465', '466', '467', '468', '469', '470', '471', '472', '473', '474', '475', '476', '477', '478', '479', '480', '481', '482', '483', '484', '485', '486', '487', '488', '489', '490', '491', '492', '493', '494', '495', '496', '497', '498', '499', '500', '501', '502', '503', '504', '505', '506', '507', '508', '509', '510', '511', '512', '513', '514', '515', '516', '517', '518', '519', '520', '521', '522', '523', '524', '525', '526', '527', '528', '529', '530', '531', '532', '533', '534', '535', '536', '537', '538', '539', '540', '541', '542', '543', '544', '545', '546', '547', '548', '549', '550', '551', '552', '553', '554', '555', '556', '557', '558', '559', '560', '561', '562', '563', '564', '565', '566', '567', '568', '569', '570', '571', '572', '573', '574', '575', '576', '577', '578', '579', '580', '581', '582', '583', '584', '585', '586', '587', '588', '589', '590', '591', '592', '593', '594', '595', '596', '597', '598', '599', '600', '601', '602', '603', '604', '605', '606', '607', '608', '609', '610', '611', '612', '613', '614', '615', '616', '617', '618', '619', '620', '621', '622', '623', '624', '625', '626', '627', '628', '629', '630', '631', '632', '633', '634', '635', '636', '637', '638', '639', '640', '641', '642', '643', '644', '645', '646', '647', '648', '649', '650', '651', '652', '653', '654', '655', '656', '657', '658', '659', '660', '661', '662', '663', '664', '665', '666', '667', '668', '669', '670', '671', '672', '673', '674', '675', '676', '677', '678', '679', '680', '681', '682', '683', '684', '685', '686', '687', '688', '689', '690', '691', '692', '693', '694', '695', '696', '697', '698', '699', '700', '701', '702', '703', '704', '705', '706', '707', '708', '709', '710', '711', '712', '713', '714', '715', '716', '717', '718', '719', '720', '721', '722', '723', '724', '725', '726', '727', '728', '729', '730', '731', '732', '733', '734', '735', '736', '737', '738', '739', '740', '741', '742', '743', '744', '745', '746', '747', '748', '749', '750', '751', '752', '753', '754', '755', '756', '757', '758', '759', '760', '761', '762', '763', '764', '765', '766', '767', '768', '769', '770', '771', '772', '773', '774', '775', '776', '777', '778', '779', '780', '781', '782', '783', '784', '785', '786', '787', '788', '789', '790', '791', '792', '793', '794', '795', '796', '797', '798', '799', '800', '801', '802', '803', '804', '805', '806', '807', '808', '809', '810', '811', '812', '813', '814', '815', '816', '817', '818', '819', '820', '821', '822', '823', '824', '825', '826', '827', '828', '829', '830', '831', '832', '833', '834', '835', '836', '837', '838', '839', '840', '841', '842', '843', '844', '845', '846', '847', '848', '849', '850', '851', '852', '853', '854', '855', '856', '857', '858', '859', '860', '861', '862', '863', '864', '865', '866', '867', '868', '869', '870', '871', '872', '873', '874', '875', '876', '877', '878', '879', '880', '881', '882', '883', '884', '885', '886', '887', '888', '889', '890', '891', '892', '893', '894', '895', '896', '897', '898', '899', '900', '901', '902', '903', '904', '905', '906', '907', '908', '909', '910', '911', '912', '913', '914', '915', '916', '917', '918', '919', '920', '921', '922', '923', '924', '925', '926', '927', '928', '929', '930', '931', '932', '933', '934', '935', '936', '937', '938', '939', '940', '941', '942', '943', '944', '945', '946', '947', '948', '949', '950', '951', '952', '953', '954', '955', '956', '957', '958', '959', '960', '961', '962', '963', '964', '965', '966', '967', '968', '969', '970', '971', '972', '973', '974', '975', '976', '977', '978', '979', '980', '981', '982', '983', '984', '985', '986', '987', '988', '989', '990', '991', '992', '993', '994', '995', '996', '997', '998', '999', '1000', '1001', '1002', '1003', '1004', '1005', '1006', '1007', '1008', '1009', '1010', '1011', '1012', '1013', '1014', '1015', '1016', '1017', '1018', '1019', '1020', '1021', '1022', '1023', '1024', '1025', '1026', '1027', '1028', '1029', '1030', '1031', '1032', '1033', '1034', '1035', '1036', '1037', '1038', '1039', '1040', '1041', '1042', '1043', '1044', '1045', '1046', '1047', '1048', '1049', '1050', '1051', '1052', '1053', '1054', '1055', '1056', '1057', '1058', '1059', '1060', '1061', '1062', '1063', '1064', '1065', '1066', '1067', '1068', '1069', '1070', '1071', '1072', '1073', '1074', '1075', '1076', '1077', '1078', '1079', '1080', '1081', '1082', '1083', '1084', '1085', '1086', '1087', '1088', '1089', '1090', '1091', '1092', '1093', '1094', '1095', '1096', '1097', '1098', '1099', '1100', '1101', '1102', '1103', '1104', '1105', '1106', '1107', '1108', '1109', '1110', '1111', '1112', '1113', '1114', '1115', '1116', '1117', '1118', '1119', '1120', '1121', '1122', '1123', '1124', '1125', '1126', '1127', '1128', '1129', '1130', '1131', '1132', '1133', '1134', '1135', '1136', '1137', '1138', '1139', '1140', '1141', '1142', '1143', '1144', '1145', '1146', '1147', '1148', '1149', '1150', '1151', '1152', '1153', '1154', '1155', '1156', '1157', '1158', '1159', '1160', '1161', '1162', '1163', '1164', '1165', '1166', '1167', '1168', '1169', '1170', '1171', '1172', '1173', '1174', '1175', '1176', '1177', '1178', '1179', '1180', '1181', '1182', '1183', '1184', '1185', '1186', '1187', '1188', '1189', '1190', '1191', '1192', '1193', '1194', '1195', '1196', '1197', '1198', '1199', '1200', '1201', '1202', '1203', '1204', '1205', '1206', '1207', '1208', '1209', '1210', '1211', '1212', '1213', '1214', '1215', '1216', '1217', '1218', '1219', '1220', '1221', '1222', '1223', '1224', '1225', '1226', '1227', '1228', '1229', '1230', '1231', '1232', '1233', '1234', '1235', '1236', '1237', '1238', '1239', '1240', '1241', '1242', '1243', '1244', '1245', '1246', '1247', '1248', '1249', '1250', '1251', '1252', '1253', '1254', '1255', '1256', '1257', '1258', '1259', '1260', '1261', '1262', '1263', '1264', '1265', '1266', '1267', '1268', '1269', '1270', '1271', '1272', '1273', '1274', '1275', '1276', '1277', '1278', '1279', '1280', '1281', '1282', '1283', '1284', '1285', '1286', '1287', '1288', '1289', '1290', '1291', '1292', '1293', '1294', '1295', '1296', '1297', '1298', '1299', '1300', '1301', '1302', '1303', '1304', '1305', '1306', '1307', '1308', '1309', '1310', '1311', '1312', '1313', '1314', '1315', '1316', '1317', '1318', '1319', '1320', '1321', '1322', '1323', '1324', '1325', '1326', '1327', '1328', '1329', '1330', '1331', '1332', '1333', '1334', '1335', '1336', '1337', '1338', '1339', '1340', '1341', '1342', '1343', '1344', '1345', '1346', '1347', '1348', '1349', '1350', '1351', '1352', '1353', '1354', '1355', '1356', '1357', '1358', '1359', '1360', '1361', '1362', '1363', '1364', '1365', '1366', '1367', '1368', '1369', '1370', '1371', '1372', '1373', '1374', '1375', '1376', '1377', '1378', '1379', '1380', '1381', '1382', '1383', '1384', '1385', '1386', '1387', '1388', '1389', '1390', '1391', '1392', '1393', '1394', '1395', '1396', '1397', '1398', '1399', '1400', '1401', '1402', '1403', '1404', '1405', '1406', '1407', '1408', '1409', '1410', '1411', '1412', '1413', '1414', '1415', '1416', '1417', '1418', '1419', '1420', '1421', '1422', '1423', '1424', '1425', '1426', '1427', '1428', '1429', '1430', '1431', '1432', '1433', '1434', '1435', '1436', '1437', '1438', '1439', '1440', '1441', '1442', '1443', '1444', '1445', '1446', '1447', '1448', '1449', '1450', '1451', '1452', '1453', '1454', '1455', '1456', '1457', '1458', '1459', '1460', '1461', '1462', '1463', '1464', '1465', '1466', '1467', '1468', '1469', '1470', '1471', '1472', '1473', '1474', '1475', '1476', '1477', '1478', '1479', '1480', '1481', '1482', '1483', '1484', '1485', '1486', '1487', '1488', '1489', '1490', '1491', '1492', '1493', '1494', '1495', '1496', '1497', '1498', '1499', '1500', '1501', '1502', '1503', '1504', '1505', '1506', '1507', '1508', '1509', '1510', '1511', '1512', '1513', '1514', '1515', '1516', '1517', '1518', '1519', '1520', '1521', '1522', '1523', '1524', '1525', '1526', '1527', '1528', '1529', '1530', '1531', '1532', '1533', '1534', '1535', '1536', '1537', '1538', '1539', '1540', '1541', '1542', '1543', '1544', '1545', '1546', '1547', '1548', '1549', '1550', '1551', '1552', '1553', '1554', '1555', '1556', '1557', '1558', '1559', '1560', '1561', '1562', '1563', '1564', '1565', '1566', '1567', '1568', '1569', '1570', '1571', '1572', '1573', '1574', '1575', '1576', '1577', '1578', '1579', '1580', '1581', '1582', '1583', '1584', '1585', '1586', '1587', '1588', '1589', '1590', '1591', '1592', '1593', '1594', '1595', '1596', '1597', '1598', '1599', '1600', '1601', '1602', '1603', '1604', '1605', '1606', '1607', '1608', '1609', '1610', '1611', '1612', '1613', '1614', '1615', '1616', '1617', '1618', '1619', '1620', '1621', '1622', '1623', '1624', '1625', '1626', '1627', '1628', '1629', '1630', '1631', '1632', '1633', '1634', '1635', '1636', '1637', '1638', '1639', '1640', '1641', '1642', '1643', '1644', '1645', '1646', '1647', '1648', '1649', '1650', '1651', '1652', '1653', '1654', '1655', '1656', '1657', '1658', '1659', '1660', '1661', '1662', '1663', '1664', '1665', '1666', '1667', '1668', '1669', '1670', '1671', '1672', '1673', '1674', '1675', '1676', '1677', '1678', '1679', '1680', '1681', '1682', '1683', '1684', '1685', '1686', '1687', '1688', '1689', '1690', '1691', '1692', '1693', '1694', '1695', '1696', '1697', '1698', '1699', '1700', '1701', '1702', '1703', '1704', '1705', '1706', '1707', '1708', '1709', '1710', '1711', '1712', '1713', '1714', '1715', '1716', '1717', '1718', '1719', '1720', '1721', '1722', '1723', '1724', '1725', '1726', '1727', '1728', '1729', '1730', '1731', '1732', '1733', '1734', '1735', '1736', '1737', '1738', '1739', '1740', '1741', '1742', '1743', '1744', '1745', '1746', '1747', '1748', '1749', '1750', '1751', '1752', '1753', '1754', '1755', '1756', '1757', '1758', '1759', '1760', '1761', '1762', '1763', '1764', '1765', '1766', '1767', '1768', '1769', '1770', '1771', '1772', '1773', '1774', '1775', '1776', '1777', '1778', '1779', '1780', '1781', '1782', '1783', '1784', '1785', '1786', '1787', '1788', '1789', '1790', '1791', '1792', '1793', '1794', '1795', '1796', '1797', '1798', '1799', '1800', '1801', '1802', '1803', '1804', '1805', '1806', '1807', '1808', '1809', '1810', '1811', '1812', '1813', '1814', '1815', '1816', '1817', '1818', '1819', '1820', '1821', '1822', '1823', '1824', '1825', '1826', '1827', '1828', '1829', '1830', '1831', '1832', '1833', '1834', '1835', '1836', '1837', '1838', '1839', '1840', '1841', '1842', '1843', '1844', '1845', '1846', '1847', '1848', '1849', '1850', '1851', '1852', '1853', '1854', '1855', '1856', '1857', '1858', '1859', '1860', '1861', '1862', '1863', '1864', '1865', '1866', '1867', '1868', '1869', '1870', '1871', '1872', '1873', '1874', '1875', '1876', '1877', '1878', '1879', '1880', '1881', '1882', '1883', '1884', '1885', '1886', '1887', '1888', '1889', '1890', '1891', '1892', '1893', '1894', '1895', '1896', '1897', '1898', '1899', '1900', '1901', '1902', '1903', '1904', '1905', '1906', '1907', '1908', '1909', '1910', '1911', '1912', '1913', '1914', '1915', '1916', '1917', '1918', '1919', '1920', '1921', '1922', '1923', '1924', '1925', '1926', '1927', '1928', '1929', '1930', '1931', '1932', '1933', '1934', '1935', '1936', '1937', '1938', '1939', '1940', '1941', '1942', '1943', '1944', '1945', '1946', '1947', '1948', '1949', '1950', '1951', '1952', '1953', '1954', '1955', '1956', '1957', '1958', '1959', '1960', '1961', '1962', '1963', '1964', '1965', '1966', '1967', '1968', '1969', '1970', '1971', '1972', '1973', '1974', '1975', '1976', '1977', '1978', '1979', '1980', '1981', '1982', '1983', '1984', '1985', '1986', '1987', '1988', '1989', '1990', '1991', '1992', '1993', '1994', '1995', '1996', '1997', '1998', '1999', '+', '=', '[PAD]', '[EOS]']\n",
      "pretokenisation of 12 + 42 = :  ['2', '1', '+', '2', '4', '=']\n"
     ]
    }
   ],
   "source": [
    "print(\"vocabulary: \", inverse_tokenizer().vocab)\n",
    "print(\"pretokenisation of 12 + 42 = : \", inverse_tokenizer().pre_tokenization(\"12 + 42 =\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a91104cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2004"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_tokenizer = inverse_tokenizer()\n",
    "ntokens_i = i_tokenizer.ntokens\n",
    "ntokens_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a8dd9639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([2, 1, 2000, 2, 4, 2001], '12+42=')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"12 + 42 =\"\n",
    "inputs = i_tokenizer.encode(prompt)\n",
    "inputs, i_tokenizer.decode(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6b6075",
   "metadata": {},
   "source": [
    "### Abacus for inverse tokeniser\n",
    "\n",
    "This code was implemented to compare my implementation with the one suggested in the Abaccus paper (https://arxiv.org/pdf/2311.14737)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8dafc437",
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_tokens = inverse_tokenizer().encode(\"0123456789\")\n",
    "\n",
    "class InverseAbacusPositionalEmbedding(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Abacus Embeddings, learned emebddings resued for each digit.\n",
    "    Integers must be reversed for this to work correctly.\n",
    "    Transformers Can Do Arithmetic with the Right Embeddings, McLeish et al. (2024)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, embedding_dim, dropout=0.5, max_seq_length=5000, max_k=99, digit_tokens=digit_tokens):\n",
    "        \"\"\"\n",
    "        digit_tokens (list): list of the tokens for each of the 10 digits\n",
    "        dropout (float): dropout rate (not used)\n",
    "        embedding_dim (int): dimension to embed into\n",
    "        max_seq_length (int): maximum number of embeddings that can be trained\n",
    "        max_k (int): maximum k value which we randomly shift by during training\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.embedding = torch.nn.Embedding(max_seq_length, embedding_dim)\n",
    "        self.register_buffer(\"digits\", torch.tensor(digit_tokens, dtype=torch.long), persistent=False)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        self.max_k = max_k\n",
    "\n",
    "    def helper(self, mask, device=device):\n",
    "        \"\"\"\n",
    "        Converts a binary mask of digit locations into spans of consecutive digits\n",
    "        \"\"\"\n",
    "        mask_shape = mask.shape\n",
    "        \n",
    "        # Create a shifted version of the mask to detect changes from 0 to 1\n",
    "        shifted_mask = torch.cat([torch.zeros((mask_shape[0], 1), device=device, dtype=mask.dtype), mask[:, :-1]], dim=1)\n",
    "        starts = (shifted_mask != mask) & mask\n",
    "        \n",
    "        # Generate IDs for each segment of 1s, processing row-wise\n",
    "        segment_ids = torch.cumsum(starts, dim=1)\n",
    "        \n",
    "        # Generate an index array row-wise\n",
    "        index = torch.arange(mask.size(1)).repeat(mask.size(0), 1).to(device)\n",
    "        \n",
    "        # Reset index at the start of each segment\n",
    "        reset_index = torch.zeros_like(mask).long()\n",
    "        second_term = index * starts.long()\n",
    "        reset_index = reset_index.scatter_add(1, segment_ids, second_term)\n",
    "        \n",
    "        # Calculate positions in segment\n",
    "        positions = index - reset_index.gather(1, segment_ids) + 1\n",
    "        \n",
    "        # Ensure only values within 1-segments are non-zero\n",
    "        result = positions * mask\n",
    "\n",
    "        return result\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        \"\"\"\n",
    "        input_ids (tensor): a batch of inputs, each row is a sample\n",
    "        \"\"\"\n",
    "        mask = torch.isin(input_ids, self.digits)\n",
    "        output = self.helper(mask, input_ids.device)\n",
    "\n",
    "        k=0\n",
    "        if self.training:\n",
    "            k = random.randint(0, self.max_k)\n",
    "            output[output>0] += k # as we already have ones in the tensor, the tensor values will be k+1\n",
    "\n",
    "        return self.embedding(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d56f5dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvTransformerModel(nn.Transformer):\n",
    "    def __init__(self, ntoken, ninp, nhead, nhid, nlayers, dropout=0.5):\n",
    "        super(InvTransformerModel, self).__init__(d_model=ninp,\n",
    "                                               nhead=nhead,\n",
    "                                               dim_feedforward=nhid,\n",
    "                                               num_encoder_layers=nlayers)\n",
    "        self.input_emb = nn.Embedding(ntoken, ninp)\n",
    "        self.pos_encoder = InverseAbacusPositionalEmbedding(ninp, dropout)\n",
    "        self.decoder = nn.Linear(ninp, ntoken)\n",
    "\n",
    "        self.ninp = ninp\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        nn.init.uniform_(self.input_emb.weight, -initrange, initrange)\n",
    "        nn.init.zeros_(self.decoder.bias)\n",
    "        nn.init.uniform_(self.decoder.weight, -initrange, initrange)\n",
    "\n",
    "    def _generate_square_subsequent_mask(self, sz):\n",
    "        return torch.log(torch.tril(torch.ones(sz,sz)))\n",
    "\n",
    "    def forward(self, src):\n",
    "        mask = self._generate_square_subsequent_mask(len(src)).to(device)\n",
    "        self.src_mask = mask\n",
    "\n",
    "        # Calcul de l'embedding d'entrée\n",
    "        src = self.input_emb(src) * math.sqrt(self.ninp)\n",
    "        # Passage à la positional encoder en fournissant les token ids\n",
    "        src = self.pos_encoder(src)\n",
    "        output_enc = self.encoder(src, mask=self.src_mask)\n",
    "        output_dec = self.decoder(output_enc)\n",
    "        return F.log_softmax(output_dec, dim=-1), output_enc"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
